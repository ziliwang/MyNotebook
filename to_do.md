### 1. 数据增强策略
 - 添加噪音，怎样添加？量？效果？其他资料？
 $$X' = X + \alpha\epsilon$$
 $$\epsilon = Normal(\mathbf 0, \mathbf 1) ? MultiNormal(\mu, \Sigma)$$
 - 数据变换：怎么变换？量？效果？其他资料？
 名词：jitter： 抖动
### 2. 噪音掺入
 - 噪音的鲁棒性，DL对噪音很敏感，参杂噪音来提高模型的robust，噪音引入不仅是在数据层面上，网络层面上也能做到
 - DL中表明，添加噪音比收缩参数更强大（正则约束），为什么？
 - 对于标注中噪音，做标签平滑
### 3. dropout
 - dropout与噪音
 - 正则约束与dropout
 - 集成学习与dropout
 - dropout的生物学意义
### 集成学习
 - 集成学习为什么有用?
 - 均值集成为什么常用的解决方案？
 - 基于重采样的集成学习方法？
### 不平衡数据
 - 训练集和测试集的概率分布不同
 - 当测试集与训练集分布不一致的时候，P、R、F1都会存在较大差别。训练集和测试集的选择，尽量跟应用场景类似。如果并不知道应用下的数据分布，如何选择训练集和测试集呢？uniform distribution？若uniform distribution下的模型，在极端分布测试集下和uniform distribution下有啥区别？（答：最后的多分类判别模型是$p(c|x)=\frac{p(x|c)p(c)}{p(x)}$,假设训练的是uniform分布，$p(c)=\frac{1}{n}$，比较的时候就可以约掉，所以最后训练的就相当于$p(c|x)$正比于$p(x|c)$）
### 十折交叉验证
 - 调超参数的
### word2vec glov fasttext
### 贝叶斯观点和最大似然的区别：
一个硬币，抛3次，三次均为正面。最大似然估计的话，下一次抛为正面的概率为1. 而贝叶斯观点，就不一了，证明？
### word2vec算法背景？解决了什么问题？怎么解决的？
#### 背景
**Distributional Hypothesis**：词的语义可以通过周边词表似。（注意，该理论是对Bag of Words Hypothesis理论的高阶近似）
Bag of Words Hypothesis：文档的词频（而不是词序）代表了文档的主题
简单来说，基于Bag of Words Hypothesis，我们可以构造一个term-document矩阵A：矩阵的行Ai,:对应着词典里的一个word；矩阵的列A:,j对应着训练语料里的一篇文档；矩阵里的元素Aij代表着word wi在文档Dj中出现的次数（或频率）。那么，我们就可以提取行向量做为word的语义向量（不过，在实际应用中，我们更多的是用列向量做为文档的主题向量）。
类似地，我们可以基于Distributional Hypothesis构造一个word-context的矩阵。此时，矩阵的列变成了context里的word，矩阵的元素也变成了一个context窗口里word的共现次数。

注意，这两类矩阵的行向量所计算的相似度有着细微的差异：term-document矩阵会给经常出现在同一篇document里的两个word赋予更高的相似度；而word-context矩阵会给那些有着相同context的两个word赋予更高的相似度。后者相对于前者是一种更高阶的相似度，因此在传统的信息检索领域中得到了更加广泛的应用。

不过，这种co-occurrence矩阵仍然存在着数据稀疏性和维度灾难的问题。为此，人们提出了一系列对矩阵进行降维的方法（如LSI／LSA等）。这些方法大都是基于SVD的思想，将原始的稀疏矩阵分解为两个低秩矩阵乘积的形式。

### glov算法背景？解决了什么问题？怎么解决的？
glov算法，词共现，优化是
### fasttext算法背景？解决了什么问题？怎么解决的？


### likelihood 和 probability的区别
1. Likelihood：用已知的（实验）数据作出（影响实验结果的）参数的函数，藉以求取参数的数值。 Probability：用已知的（影响实验结果的）参数作出（能够预测实验结果的）函数，藉以预测实验的结果。
1. 概率（probability)和似然（likelihood)，都是指可能性，都可以被称为概率，但在统计应用中有所区别。
   - 概率是给定某一参数值，求某一结果的可能性的函数。
   例如，抛一枚匀质硬币，抛10次，6次正面向上的可能性多大？
   解读：“匀质硬币”，表明参数值是0.5，“抛10次，六次正面向上”这是一个结果，概率（probability)是求这一结果的可能性。
   - 似然是给定某一结果，求某一参数值的可能性的函数。
   例如，抛一枚硬币，抛10次，结果是6次正面向上，其是匀质的可能性多大？
   解读：“抛10次，结果是6次正面向上”，这是一个给定的结果，问“匀质”的可能性，即求参数值=0.5的可能性。
